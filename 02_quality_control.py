# 02_quality_control.py
import subprocess
import os
import pandas as pd

# --- Configuration ---
BASE_DATA_PATH = 'public' # Assuming 'public' folder is in the same dir as script
# Base PLINK filesets (before any QC by this script)
# These should be the raw files provided in the iOmics dataset for each population
# e.g., "110Chinese_2527458snps" (without .bed/bim/fam extension)
raw_plink_files_info = {
    'Chinese': os.path.join(BASE_DATA_PATH, 'Genomics', '110Chinese_2527458snps'),
    'Malay': os.path.join(BASE_DATA_PATH, 'Genomics', '108Malay_2527458snps'),
    'Indian': os.path.join(BASE_DATA_PATH, 'Genomics', '105Indian_2527458snps')
}

# Phenotype files generated by 01_data_preparation.py
pheno_files_dir = 'prepared_data'
pheno_files = {
    'Chinese': os.path.join(pheno_files_dir, 'chinese_pheno.txt'),
    'Malay': os.path.join(pheno_files_dir, 'malay_pheno.txt'),
    'Indian': os.path.join(pheno_files_dir, 'indian_pheno.txt')
}
# Name of the phenotype column in the files generated by script 01
# (Must match the header used in those files, e.g., TARGET_PHENOTYPE_COL from script 01)
PHENOTYPE_NAME_IN_FILE = 'Cholesterol' # This was set as header in 01_data_preparation.py

# QC parameters (aligning somewhat with R script's stringency, but adaptable)
# R script was very stringent (MAF 0.1, Call Rate 1).
# For ML, we might want slightly less stringency initially.
MAF_THRESHOLD = 0.05       # Minor Allele Frequency
GENO_MISSING_THRESHOLD = 0.1 # Max per-SNP missingness
MIND_MISSING_THRESHOLD = 0.1 # Max per-individual missingness
HWE_THRESHOLD = 1e-6       # Hardy-Weinberg Equilibrium p-value
LD_WINDOW_KB = 50          # LD pruning window size in kb
LD_STEP_SIZE = 5           # LD pruning window step size (SNPs)
LD_R_SQUARED_THRESHOLD = 0.2 # LD pruning r^2 threshold (R script used 0.2)

# Output directories
qc_output_dir = 'qc_data'
pca_output_dir = 'pca_data'
os.makedirs(qc_output_dir, exist_ok=True)
os.makedirs(pca_output_dir, exist_ok=True)

# Path to PLINK executable (user might need to change this)
PLINK_EXECUTABLE = 'plink/plink.exe' # Or full path e.g., '/usr/local/bin/plink' or 'C:\\plink\\plink.exe'

def run_plink_command(command_args, log_prefix):
    """Runs a PLINK command and logs output."""
    try:
        print(f"Running PLINK: {' '.join(command_args)}")
        process = subprocess.Popen(command_args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
        log_filename = f"{log_prefix}.log"
        with open(log_filename, 'w') as log_file:
            for line in process.stdout:
                print(line, end='') # Print to console
                log_file.write(line) # Write to log file
        process.wait()
        if process.returncode != 0:
            print(f"ERROR: PLINK command failed with exit code {process.returncode}. See {log_filename}")
            return False
        print(f"PLINK command successful. Log: {log_filename}")
        return True
    except FileNotFoundError:
        print(f"ERROR: PLINK executable ('{PLINK_EXECUTABLE}') not found. Please check path or install PLINK.")
        return False
    except Exception as e:
        print(f"ERROR running PLINK: {e}")
        return False

# --- 1. Per-Population QC ---
print("\n--- Starting Per-Population QC ---")
qc_pop_filesets = {} # To store paths to final QC'd files for each pop

for pop, raw_bfile_prefix in raw_plink_files_info.items():
    print(f"\nProcessing {pop}...")
    pheno_file = pheno_files.get(pop)
    if not (pheno_file and os.path.exists(pheno_file)):
        print(f"WARNING: Phenotype file for {pop} not found at {pheno_file}. Some QC steps might be affected or GWAS later will fail.")
        # Continue QC but be aware
    
    current_bfile = raw_bfile_prefix
    step_prefix = os.path.join(qc_output_dir, f"{pop.lower()}_s0_raw")

    # Step 0: Make a working copy and associate phenotype for filtering if needed
    # (especially important if MIND_MISSING_THRESHOLD depends on phenotype presence)
    # Also, ensure we only keep samples that have phenotype data.
    # The R script matches samples *before* QC. We can do that here too.
    pheno_ids_df = pd.read_csv(pheno_file, sep='\t', usecols=['FID', 'IID'])
    keep_samples_file = os.path.join(qc_output_dir, f"{pop.lower()}_pheno_samples.txt")
    pheno_ids_df.to_csv(keep_samples_file, sep='\t', index=False, header=False)

    cmd_args_keep = [PLINK_EXECUTABLE, '--bfile', current_bfile, '--keep', keep_samples_file, '--make-bed', '--out', step_prefix]
    if not run_plink_command(cmd_args_keep, f"{qc_output_dir}/{pop.lower()}_log_keep"): continue
    current_bfile = step_prefix
    
    # Step 1: Basic filters (MAF, HWE, geno)
    step1_prefix = os.path.join(qc_output_dir, f"{pop.lower()}_s1_maf_hwe_geno")
    cmd_args1 = [PLINK_EXECUTABLE, '--bfile', current_bfile,
                 '--maf', str(MAF_THRESHOLD),
                 '--hwe', str(HWE_THRESHOLD), 'midp', # midp recommended for HWE
                 '--geno', str(GENO_MISSING_THRESHOLD),
                 '--make-bed', '--out', step1_prefix]
    if not run_plink_command(cmd_args1, f"{qc_output_dir}/{pop.lower()}_log_s1"): continue
    current_bfile = step1_prefix

    # Step 2: Individual missingness
    step2_prefix = os.path.join(qc_output_dir, f"{pop.lower()}_s2_mind")
    cmd_args2 = [PLINK_EXECUTABLE, '--bfile', current_bfile,
                 '--mind', str(MIND_MISSING_THRESHOLD),
                 '--make-bed', '--out', step2_prefix]
    if not run_plink_command(cmd_args2, f"{qc_output_dir}/{pop.lower()}_log_s2"): continue
    current_bfile = step2_prefix
    
    # Step 3: LD Pruning (on this QC'd set for this population)
    step3_ld_prefix = os.path.join(qc_output_dir, f"{pop.lower()}_s3_ldprune")
    cmd_args_indep = [PLINK_EXECUTABLE, '--bfile', current_bfile,
                      '--indep-pairwise', f"{LD_WINDOW_KB}kb", str(LD_STEP_SIZE), str(LD_R_SQUARED_THRESHOLD),
                      '--out', step3_ld_prefix]
    if not run_plink_command(cmd_args_indep, f"{qc_output_dir}/{pop.lower()}_log_s3_indep"): continue
    
    step3_extract_prefix = os.path.join(qc_output_dir, f"{pop.lower()}_s3_ldpruned_final")
    cmd_args_extract = [PLINK_EXECUTABLE, '--bfile', current_bfile,
                        '--extract', f"{step3_ld_prefix}.prune.in",
                        '--make-bed', '--out', step3_extract_prefix]
    if not run_plink_command(cmd_args_extract, f"{qc_output_dir}/{pop.lower()}_log_s3_extract"): continue
    qc_pop_filesets[pop] = step3_extract_prefix # Store the final LD-pruned set for this pop
    print(f"Finished QC for {pop}. Final LD-pruned fileset: {qc_pop_filesets[pop]}")

# --- 2. Merge Populations for PCA ---
# We merge the Step 2 files (after MAF, HWE, geno, mind QC but *before* per-population LD pruning)
# to get a common set of SNPs for PCA, then LD prune the merged set.
print("\n--- Preparing for PCA on Merged Data ---")
merge_list_file = os.path.join(pca_output_dir, 'merge_list.txt')
intermediate_merged_files = []
with open(merge_list_file, 'w') as f:
    first_pop = True
    for i, pop in enumerate(raw_plink_files_info.keys()):
        # Use the output from Step 2 (mind filter) for merging
        pop_s2_bfile = os.path.join(qc_output_dir, f"{pop.lower()}_s2_mind")
        if os.path.exists(f"{pop_s2_bfile}.bed"):
            if first_pop:
                # The first file in the list doesn't need to be listed itself if it's the primary --bfile for merge
                first_pop = False
            else:
                f.write(f"{pop_s2_bfile}\n") # PLINK expects .bed .bim .fam, just prefix is fine for merge list
            intermediate_merged_files.append(pop_s2_bfile)
        else:
            print(f"WARNING: {pop_s2_bfile}.bed not found. Cannot include in merge for PCA.")

merged_bfile_for_pca_unpruned = os.path.join(pca_output_dir, 'merged_for_pca_unpruned')
if len(intermediate_merged_files) >= 2:
    # The first file in intermediate_merged_files will be the primary --bfile
    # The rest will be in merge_list_file
    primary_bfile_for_merge = intermediate_merged_files[0]
    files_to_merge_in_list = intermediate_merged_files[1:]
    
    with open(merge_list_file, 'w') as f_ml:
        for file_prefix in files_to_merge_in_list:
            f_ml.write(f"{file_prefix}\n")

    cmd_args_merge = [PLINK_EXECUTABLE, '--bfile', primary_bfile_for_merge,
                      '--merge-list', merge_list_file,
                      '--make-bed', '--out', merged_bfile_for_pca_unpruned]
    # PLINK merge can be tricky with SNP mismatches (strand, pos, alleles)
    # It might create .missnp files. A more robust merge might require pre-processing SNPs.
    # For now, we attempt a direct merge.
    if not run_plink_command(cmd_args_merge, f"{pca_output_dir}/log_merge_for_pca"):
        print("ERROR: Merging populations for PCA failed. PCA cannot proceed.")
        # Check for .missnp file if merge fails
        if os.path.exists(f"{merged_bfile_for_pca_unpruned}-merge.missnp"):
            print(f"SNP mismatch issues found. See: {merged_bfile_for_pca_unpruned}-merge.missnp")
            print("You may need to flip/exclude problematic SNPs before merging.")
        pca_success = False
    else:
        pca_success = True
elif len(intermediate_merged_files) == 1:
    print("Only one population's data available after QC step 2. Running PCA on this single population.")
    # Just copy/rename the single file to be the input for PCA LD pruning
    cmd_copy = [PLINK_EXECUTABLE, '--bfile', intermediate_merged_files[0], '--make-bed', '--out', merged_bfile_for_pca_unpruned]
    if not run_plink_command(cmd_copy, f"{pca_output_dir}/log_copy_for_pca"): pca_success = False
    else: pca_success = True
else:
    print("ERROR: Not enough population data available to merge for PCA.")
    pca_success = False

if pca_success:
    # LD Prune the merged dataset before PCA
    merged_ld_prefix = os.path.join(pca_output_dir, 'merged_for_pca_ldprune')
    cmd_args_merged_indep = [PLINK_EXECUTABLE, '--bfile', merged_bfile_for_pca_unpruned,
                             '--indep-pairwise', f"{LD_WINDOW_KB}kb", str(LD_STEP_SIZE), str(LD_R_SQUARED_THRESHOLD),
                             '--out', merged_ld_prefix]
    if not run_plink_command(cmd_args_merged_indep, f"{pca_output_dir}/log_merged_ldprune"): pca_success = False
    else:
        merged_ldpruned_bfile = os.path.join(pca_output_dir, 'merged_for_pca_ldpruned_final')
        cmd_args_merged_extract = [PLINK_EXECUTABLE, '--bfile', merged_bfile_for_pca_unpruned,
                                   '--extract', f"{merged_ld_prefix}.prune.in",
                                   '--make-bed', '--out', merged_ldpruned_bfile]
        if not run_plink_command(cmd_args_merged_extract, f"{pca_output_dir}/log_merged_ldextract"): pca_success = False
        else:
            # Run PCA
            pca_output_prefix = os.path.join(pca_output_dir, 'merged_pca')
            # Output N principal components, e.g., 10 or 20
            cmd_args_pca = [PLINK_EXECUTABLE, '--bfile', merged_ldpruned_bfile,
                            '--pca', '10', 'header', # 'header' includes FID, IID in output
                            '--out', pca_output_prefix]
            if not run_plink_command(cmd_args_pca, f"{pca_output_dir}/log_pca"): pca_success = False
            else:
                print(f"PCA successful. Eigenvectors written to {pca_output_prefix}.eigenvec")
                # Add PCs to the covariate file
                covariate_file_path = os.path.join(pheno_files_dir, 'covariates.txt')
                pca_eigenvec_file = f"{pca_output_prefix}.eigenvec"
                if os.path.exists(covariate_file_path) and os.path.exists(pca_eigenvec_file):
                    cov_df = pd.read_csv(covariate_file_path, sep='\t', dtype={'FID': str, 'IID': str})
                    pca_df = pd.read_csv(pca_eigenvec_file, sep='\s+', dtype={'FID': str, 'IID': str})
                    # Ensure FID and IID are strings for merging
                    
                    # Drop the first two columns of pca_df if they are FID, IID, PLINK 1.9 output has #FID IID
                    # PLINK 2.0 output might just be FID IID PC1...
                    # Check header carefully for actual column names.
                    # Assuming header from PLINK '--pca N header' is like: FID IID PC1 PC2 ...
                    # If it's #FID IID PC1... need to handle the '#'
                    if pca_df.columns[0].startswith('#'): # Handle PLINK 2.0 header
                         pca_df = pca_df.rename(columns={pca_df.columns[0]: 'FID', pca_df.columns[1]: 'IID'})
                    
                    # Select only PC columns for merging, FID and IID are keys
                    pc_cols_to_merge = ['FID', 'IID'] + [col for col in pca_df.columns if col.startswith('PC')]
                    pca_df_subset = pca_df[pc_cols_to_merge]

                    cov_df = pd.merge(cov_df, pca_df_subset, on=['FID', 'IID'], how='left')
                    cov_df.to_csv(covariate_file_path, sep='\t', index=False, header=True)
                    print(f"Updated covariate file {covariate_file_path} with PCs.")
                else:
                    print("WARNING: Covariate file or PCA eigenvector file not found. Cannot add PCs.")
else:
    print("PCA could not be completed due to earlier errors.")

print("\n--- Quality Control and PCA Script Finished ---")
print("Per-population QC'd and LD-pruned filesets are in:", qc_output_dir)
if pca_success:
    print("PCA results are in:", pca_output_dir)
    print("Covariate file updated with PCs (if successful):", os.path.join(pheno_files_dir, 'covariates.txt'))